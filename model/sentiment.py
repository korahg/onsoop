# sentiment.py (ë¯¸ì„¸ íŠœë‹ï¼‹ì™¸ë¡œì›€ ë³´ê°•)
import os
import re
import numpy as np
import torch
from typing import Dict
from transformers import AutoTokenizer, AutoModelForSequenceClassification

from model.crisis_intervention import (
    check_crisis_message, check_simple_emotion, check_contrast_emotion
)

EMO_DIR = 'models/emotions_kor'
EMOS = ['ê³µí¬', 'ë†€ëžŒ', 'ë¶„ë…¸', 'ìŠ¬í””', 'ì¤‘ë¦½', 'í–‰ë³µ', 'í˜ì˜¤']

_e_tok = _e_mod = None

# ---- ìƒ¤í”„ë‹/ê·œì¹™ ê°€ì‚° ê¸°ë³¸ê°’
GAMMA = 1.25
RULE_BOOST = {
    'ê³µí¬': 0.18, 'ë†€ëžŒ': 0.15, 'ë¶„ë…¸': 0.25,
    'ìŠ¬í””': 0.30, 'ì¤‘ë¦½': 0.10, 'í–‰ë³µ': 0.28, 'í˜ì˜¤': 0.22,
}
INTENSIFIERS = ['ë„ˆë¬´','ë§¤ìš°','ì—„ì²­','ì •ë§','ì§„ì§œ','ì™„ì „','ë˜ê²Œ','ê°œ','ì¡´ë‚˜','ì¡¸ë¼','ëŒ€ë°•','í‚¹ë°›','ê°œë¹¡','ê°œë¬´ì„­']
DIMINISHERS = ['ì¢€','ì¡°ê¸ˆ','ì•½ê°„','ê·¸ëŸ­ì €ëŸ­','ê·¸ëƒ¥','ì‚´ì§','ê´œì°®']
NEGATIONS = ['ì•„ë‹ˆ','ì•ˆ ','ì•Š','ë³„ë¡œ','ì „í˜€','ê·¸ë ‡ì§„','ê·¸ë ‡ì§€ ì•Š','ì•„ëƒ','ì•„ë‹Œ','ì—†','ëª» ']
CONTRASTORS = ['í•˜ì§€ë§Œ','ê·¸ëž˜ë„','ê·¼ë°','ê·¸ëŸ¬ë‚˜']

LEX = {
    'ìŠ¬í””': ['í—ˆë§','í—ˆë¬´','í—ˆíƒˆ','í˜„íƒ€','ìƒì‹¤','ì¢Œì ˆ','íŒ¨ë°°ê°','ëˆˆë¬¼','ìš¸ì»¥','ì˜¤ì—´','ìŠ¬í”„','ë¹„í†µ','ìš°ìš¸','ê³µí—ˆ','ì™¸ë¡­','ì ë§‰','ë§‰ë§‰','ë¬´ë ¥ê°','íž˜ë“¤','ì§€ì³¤','ì„œê¸€í”„'],
    'ê³µí¬': ['ë¶ˆì•ˆ','ê±±ì •','ë‘ë µ','ê²ë‚˜','ê²ì´','ì´ˆì¡°','ê¸´ìž¥','ëœì»¥','ë¶ˆê¸¸','ë¬´ì„­','ì†Œë¦„','ë¶ˆíŽ¸í•˜','ì´ˆì¡°í•˜'],
    'ë¶„ë…¸': ['ë¶„ë…¸','í™”ê°€','í™”ë‚¨','ì§œì¦','ì–µìš¸','ë¶€ë“¤','ì—´ë°›','ë¹¡ì¹˜','ë¹¡ì³','ë¹¡ì¹¨','ì„±ì§ˆ','í™”ë”±ì§€','ê°œë¹¡','ë¯¸ì¹˜ê² ','Xê°™','ì¢†ê°™','ì”¨ë°œ','ì‹œë°œ'],
    'í˜ì˜¤': ['í˜ì˜¤','ì—­ê²¹','ì§•ê·¸','êµ¬ì—­ì§ˆ','ë¶ˆê²°','ë”ëŸ½','í† ë‚˜','ë¹„ìœ„ê°€'],
    'ë†€ëžŒ': ['ë†€ëž','ì¶©ê²©','ê²½ì•…','ì–´ì´ì—†','í—','ì„¸ìƒì—','ë§ë„ì•ˆë¼','ë¯¿ê¸°ì§€','ê¹œì§','í—‰'],
    'í–‰ë³µ': ['í–‰ë³µ','ê¸°ì˜','ì¢‹ì•„','ì¢‹ë‹¤','ì„¤ë ˜','ì„¤ë Œ','ì¦ê²','ë¿Œë“¯','ê°ì‚¬','ì‚¬ëž‘','ì‚¬ëž‘í•´','íŽ¸ì•ˆ','ë“ ë“ ','ìœ„ë¡œê°€ ë¼','ìœ„ì•ˆ'],
}

EMOJI_MAP = {
    'ìŠ¬í””': ['ðŸ˜­','ðŸ˜¢','ã…œã…œ','ã… ã… ','í‘í‘','ì—‰ì—‰','T_T','TT',';_;'],
    'ê³µí¬': ['ðŸ˜±','ðŸ˜¨','ë¬´ì„œì›Œ','ëœëœ','ã„·ã„·','ë¬´ì„­'],
    'ë¶„ë…¸': ['ðŸ˜¡','ðŸ¤¬','í™”ë‚˜','ë¹¡ì¹¨','ì—´ë°›'],
    'í–‰ë³µ': ['ðŸ˜Š','ðŸ˜„','ðŸ˜','ðŸ˜','ðŸ¤—','ã…Žã…Ž','ã…‹ã…‹','^^','^_^'],
    'ë†€ëžŒ': ['ðŸ˜²','ðŸ˜®','í—‰','í—','ì™€ìš°'],
    'í˜ì˜¤': ['ðŸ¤¢','ðŸ¤®'],
}

FEAR_QUESTIONS = ['ì–´ë–¡í•˜','ì–´ì©Œ','ë¶ˆì•ˆí•´','ê´œì°®ì„ê¹Œ','ë¬´ì„œìš¸','ì£½ê² ']
SADNESS_PHRASES = ['ì™œ ë‚˜ë§Œ','í¬ê¸°í•˜ê³  ì‹¶','ì‚´ê¸° ì‹«','ë”ëŠ” ëª»','í¬ë§ì´ ì—†','í¬ë§ ì—†ë‹¤']

# â–¶ ì™¸ë¡œì›€/ê³ ë… íŒ¨í„´(ì •ê·œì‹)
LONELY_PATTERNS = [
    r'ì™¸ë¡­[ë‹¤ìš”]?', r'ì™¸ë¡œì›€', r'ì“¸ì“¸', r'ê³ ë…',
    r'í˜¼ìž(ì•¼|ë¼ì„œ|ë§Œ|ì„œ)',                    # í˜¼ìžì•¼/í˜¼ìžë¼ì„œ/í˜¼ìžë§Œ/í˜¼ìžì„œ
    r'(ì¹œí•œ|ê°€ê¹Œìš´)[^ê°€-íž£]{0,2}ì‚¬ëžŒì´ ì—†',      # ì¹œí•œ ì‚¬ëžŒì´ ì—†ì–´
    r'ì—°ë½(í• |í•˜[ëŠ”ã„´]) ì‚¬ëžŒì´ ì—†',             # ì—°ë½í• /í•˜ëŠ” ì‚¬ëžŒì´ ì—†
]
FEAR_HINTS = ['ë¶ˆì•ˆ','ê±±ì •','ë‘ë µ','ê²ë‚˜','ë¬´ì„­','ì´ˆì¡°','ê¸´ìž¥']

def _contains_any(text: str, words: list[str]) -> bool:
    t = text.lower()
    return any(w.lower() in t for w in words)

def _negated_near(text: str, keyword: str, window: int = 3) -> bool:
    t = text
    idx = t.find(keyword)
    if idx == -1:
        return False
    left = t[max(0, idx - window*2): idx+1]
    return any(ng in left for ng in NEGATIONS)

def _intensity_multiplier(text: str) -> float:
    mult = 1.0
    if _contains_any(text, INTENSIFIERS): mult *= 1.35
    if _contains_any(text, DIMINISHERS): mult *= 0.75
    if '!!' in text or '???' in text: mult *= 1.15
    return mult

def _emoji_boost(text: str, acc: Dict[str, float]):
    for emo, marks in EMOJI_MAP.items():
        if _contains_any(text, marks):
            acc[emo] = acc.get(emo, 0.0) + RULE_BOOST.get(emo, 0.2)

def _contrast_dampen(text: str, acc: Dict[str, float]):
    if _contains_any(text, CONTRASTORS):
        for k in acc: acc[k] *= 0.9

def adjust_with_rules(text: str, probs: Dict[str, float]) -> Dict[str, float]:
    out = {k: float(max(0.0, probs.get(k, 0.0))) for k in EMOS}
    t = (text or "").strip()
    if not t:
        s = sum(out.values()) or 1.0
        return {k: v / s for k, v in out.items()}

    # 1) í‚¤ì›Œë“œ ê°€ì‚° (+ë¶€ì • ì•½í™”)
    for emo, kws in LEX.items():
        for kw in kws:
            if kw in t:
                boost = RULE_BOOST.get(emo, 0.2)
                if _negated_near(t, kw): boost *= 0.35
                out[emo] = min(1.0, out.get(emo, 0.0) + boost)

    # 2) ì™¸ë¡œì›€/ê³ ë… íŒ¨í„´ â†’ ìŠ¬í”” í¬ê²Œ ë³´ê°•
    if any(re.search(p, t) for p in LONELY_PATTERNS):
        out['ìŠ¬í””'] = min(1.0, out.get('ìŠ¬í””', 0.0) + 0.25)
        # ê³µí¬ ë‹¨ì„œ ê±°ì˜ ì—†ìœ¼ë©´ ìŠ¬í”” ì¶”ê°€ + ê³µí¬ ì•½í™”
        if not any(h in t for h in FEAR_HINTS):
            out['ìŠ¬í””'] = min(1.0, out.get('ìŠ¬í””', 0.0) + 0.15)
            out['ê³µí¬'] = max(0.0, out.get('ê³µí¬', 0.0) - 0.10)

    # 3) í—ˆë¬´/ìƒì‹¤ + ë¶ˆì•ˆ ê³µì¡´ ì‹œ ìŠ¬í”” ìª½ìœ¼ë¡œ ê°€ì¤‘
    if _contains_any(t, ['í—ˆë§','í—ˆë¬´','í—ˆíƒˆ','ìƒì‹¤','ê³µí—ˆ','í˜„íƒ€']) and _contains_any(t, ['ë¶ˆì•ˆ','ê±±ì •','ë‘ë µ','ë¬´ì„­']):
        out['ìŠ¬í””'] = min(1.0, out.get('ìŠ¬í””', 0.0) + 0.18)

    # 4) ì˜ë¬¸/í˜¸ì†Œ íŒ¨í„´
    if _contains_any(t, FEAR_QUESTIONS): out['ê³µí¬'] = min(1.0, out.get('ê³µí¬', 0.0) + 0.12)
    if _contains_any(t, SADNESS_PHRASES): out['ìŠ¬í””'] = min(1.0, out.get('ìŠ¬í””', 0.0) + 0.15)

    # 5) ì´ëª¨ì§€/ê°•ë„/ëŒ€ë¹„ ì ‘ì†ì‚¬
    _emoji_boost(t, out)
    mult = _intensity_multiplier(t)
    for k in out: out[k] *= mult
    _contrast_dampen(t, out)

    # 6) ã… /ã…œ ë°˜ë³µ â†’ ìŠ¬í”” ì†Œí­ ë³´ê°•
    tears = len(re.findall(r'(ã… ã… |ã…œã…œ|ã… |ã…œ)', t))
    if tears >= 2: out['ìŠ¬í””'] = min(1.0, out.get('ìŠ¬í””', 0.0) + 0.05 * min(tears, 5))

    # 7) ìƒ¤í”„ë‹ + ì •ê·œí™” + ê·¹ë‹¨ì¹˜ í´ëž¨í”„
    vec = np.array([max(1e-8, out[k]) for k in EMOS], dtype=float) ** GAMMA
    s = float(vec.sum())
    if s > 0: vec /= s
    vec = np.clip(vec, 0.0, 0.95)
    vec = vec / (vec.sum() or 1.0)

    return {EMOS[i]: float(round(vec[i], 6)) for i in range(len(EMOS))}

# ---- ëª¨ë¸ ë¡œë“œ/ì¶”ë¡ 
def _safe_load(model_id):
    try:
        tok = AutoTokenizer.from_pretrained(model_id, local_files_only=True)
        mod = AutoModelForSequenceClassification.from_pretrained(model_id, local_files_only=True)
        print(f"[sentiment] âœ… '{model_id}' ëª¨ë¸ ë¡œë”© ì„±ê³µ.")
        return tok, mod
    except Exception as e:
        print(f"[sentiment] âŒ '{model_id}' ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨. ì—ëŸ¬: {repr(e)}")
        return None, None

def init_models():
    global _e_tok, _e_mod
    if _e_tok is None:
        _e_tok, _e_mod = _safe_load(EMO_DIR)

def analyze_emotion(text: str) -> Dict:
    crisis_result = check_crisis_message(text)
    if crisis_result: return crisis_result

    contrast_result = check_contrast_emotion(text)
    if contrast_result: return contrast_result

    simple_result = check_simple_emotion(text)
    if simple_result: return simple_result

    if not _e_tok or not _e_mod or not text or not text.strip():
        return {"emotions": {e: 0.0 for e in EMOS}}

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    _e_mod.to(device)

    inputs = _e_tok(text, return_tensors='pt', truncation=True, padding=True, max_length=128).to(device)
    with torch.no_grad():
        logits = _e_mod(**inputs).logits

    probabilities = torch.softmax(logits, dim=-1).cpu().numpy()[0]
    raw_emotions = {EMOS[i]: float(probabilities[i]) for i in range(len(EMOS))}
    emotions = adjust_with_rules(text, raw_emotions)

    return {"emotions": emotions}
